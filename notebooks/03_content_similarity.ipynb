{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38cbdae9-6c14-4364-8aac-32043ec7bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "391a8c07-3857-4c50-b613-596d0f5bc1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# ðŸ“‚ Step 1: Load Cleaned Data\n",
    "# ===============================\n",
    "# Load news articles with preprocessed content\n",
    "df_news = pd.read_csv('clean_news.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee18d8d6-47ea-45d3-a0bf-53ddcd3c8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved TF-IDF matrix and vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "139ba688-ba2f-4ad6-adb9-c923ccefa00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TF-IDF matrix from clean content\n",
      "TF-IDF matrix shape: (51282, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load or transform the text data to TF-IDF matrix\n",
    "# If the TF-IDF matrix is already computed and saved\n",
    "try:\n",
    "    # Try to load the pre-computed TF-IDF matrix\n",
    "    tfidf_matrix = sp.load_npz('tfidf_matrix.npz')\n",
    "    print(\"Loaded pre-computed TF-IDF matrix\")\n",
    "except FileNotFoundError:\n",
    "    # If not found, compute it from the clean content\n",
    "    print(\"Computing TF-IDF matrix from clean content\")\n",
    "    tfidf_matrix = tfidf_vectorizer.transform(df_news['clean_content'])\n",
    "    # Optionally save for future use\n",
    "    sp.save_npz('tfidf_matrix.npz', tfidf_matrix)\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bac26d86-26cd-48ad-89b7-3fd71494f1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User profile vector shape: (1, 8)\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# ðŸ“‚ Step 2: Load User Profile Vector\n",
    "# ===============================\n",
    "try:\n",
    "    with open('user_profile_vector.pkl', 'rb') as f:\n",
    "        user_profile_vector = pickle.load(f)\n",
    "    \n",
    "    # Make sure the user profile is in the correct format\n",
    "    # It should be a 2D array or sparse matrix with shape (1, n_features)\n",
    "    if isinstance(user_profile_vector, np.ndarray):\n",
    "        # Convert to 2D array if it's 1D\n",
    "        if user_profile_vector.ndim == 1:\n",
    "            user_profile_vector = user_profile_vector.reshape(1, -1)\n",
    "    elif isinstance(user_profile_vector, csr_matrix):\n",
    "        # If it's already a sparse matrix, ensure it's 2D\n",
    "        if user_profile_vector.shape[0] != 1:\n",
    "            user_profile_vector = user_profile_vector.reshape(1, -1)\n",
    "    else:\n",
    "        raise TypeError(\"User profile vector must be a numpy array or sparse matrix\")\n",
    "    \n",
    "    print(\"User profile vector shape:\", user_profile_vector.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"The file 'user_profile_vector.pkl' was not found.\")\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb55efe4-b996-4bfd-8230-40d193f61eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully computed similarity scores for 51282 articles\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "try:\n",
    "    # Convert user_profile_vector to numpy array\n",
    "    if isinstance(user_profile_vector, np.matrix):\n",
    "        user_profile_vector = np.asarray(user_profile_vector).reshape(1, -1)\n",
    "    \n",
    "    # Convert tfidf_matrix to dense array if it's sparse\n",
    "    if isinstance(tfidf_matrix, csr_matrix):\n",
    "        tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "    else:\n",
    "        tfidf_matrix_dense = np.asarray(tfidf_matrix)\n",
    "    \n",
    "    # Compute cosine similarity between user profile and all articles\n",
    "    similarity_scores = cosine_similarity(user_profile_vector, tfidf_matrix_dense)\n",
    "    \n",
    "    # Flatten the result to 1D array\n",
    "    similarity_scores = similarity_scores.flatten()\n",
    "    \n",
    "    print(f\"Successfully computed similarity scores for {len(similarity_scores)} articles\")\n",
    "except Exception as e:\n",
    "    print(f\"Error computing cosine similarity: {e}\")\n",
    "    print(\"\\nDebug information:\")\n",
    "    print(f\"  - user_profile_vector type: {type(user_profile_vector)}\")\n",
    "    print(f\"  - tfidf_matrix type: {type(tfidf_matrix)}\")\n",
    "    exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ee1fad6-f8e5-48c3-a459-51fcb0785903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in df_news_sorted: Index(['news_id', 'category', 'subcategory', 'clean_content',\n",
      "       'similarity_score'],\n",
      "      dtype='object')\n",
      "\n",
      "Top 5 most similar articles:\n",
      "KeyError: \"['title'] not in index\". Please check the column names in the dataframe.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# ðŸ“Š Step 4: Add Similarity Scores\n",
    "# ===============================\n",
    "# Add similarity scores to the news dataframe\n",
    "df_news['similarity_score'] = similarity_scores\n",
    "\n",
    "# Sort by score (highest first)\n",
    "df_news_sorted = df_news.sort_values(by='similarity_score', ascending=False)\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"Column names in df_news_sorted:\", df_news_sorted.columns)\n",
    "\n",
    "# Show top 5 most similar articles\n",
    "try:\n",
    "    print(\"\\nTop 5 most similar articles:\")\n",
    "    print(df_news_sorted[['news_id', 'title', 'category', 'similarity_score']].head())\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}. Please check the column names in the dataframe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d5c3fd-6aab-49a2-bfa7-052ba3a6cd63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
